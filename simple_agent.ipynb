{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE AGENT\n",
    "\n",
    "This simple agent is similar to the tool agent (both of them are based on their past knowledge).\n",
    "The difference is that this agent doesn't have a  tool and tries to generate a cypher query to retrieve the data to answer the question.\n",
    "The query is not executed, this was a first step to test how prompt can be useful too.\n",
    "If you don't provide, for example, the schema of the database the generated query can be general and should be changed to be run in a real database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, register_function, config_list_from_json\n",
    "from tools.neo4j_tools import * # Imports all the functions\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LLM MODEL CONFIGURATION ####\n",
    "\n",
    "config_list = config_list_from_json(env_or_file=\"CONFIG_LIST\", filter_dict={\"model\": \"gpt-4o\"})\n",
    "config_list[0][\"api_key\"] = os.environ.get(\"GITHUB_TOKEN\")\n",
    "\n",
    "# This simple prompt will give some advice to the model on how to do things.\n",
    "# In this very simple version, the database schema is hard-coded.\n",
    "prompt = \"\"\"You are an AI helpful assistant.\n",
    "\n",
    "### RULES ###\n",
    "    - You have to explain everything you do.\n",
    "    - When the question refers to something that might be contained \n",
    "      in the database you must generate the query to retrieve that data.\n",
    "    - When generating a query you must use the Cypher format.\n",
    "\n",
    "### TERMINATION ###\n",
    "You can add 'TERMINATE' at the end of your message if:\n",
    "    - You didn't respond with a query.\n",
    "    - You think the query do not generate errors.\n",
    "\n",
    "### DATABASE SCHEMA ### \n",
    "- nodes -\n",
    "(:Movie), Describe a movie that has a title and a plot. It can also have the number of likes.\n",
    "(:Person), Describe actors and directors. They have a name, a birthday and they may also have the death date.\n",
    "\n",
    "- relationships -\n",
    "(:Movie) <-[:DIRECTED]- (:Person)\n",
    "(:Person) -[:ACTED-IN]-> (:Movie)\n",
    "(:Person) -[:KNOWS]-> (:Person)\n",
    "(:Movie) -[:type]-> (:Genre)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question starts the conversation asking a simple question\n",
    "question = ConversableAgent(\n",
    "    \"question\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg[\"content\"].lower(),\n",
    ")\n",
    "\n",
    "# coder will try to translate the question from natural language to cypher \n",
    "coder = ConversableAgent(\n",
    "    \"coder\",\n",
    "    system_message = prompt,\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg[\"content\"].lower(),\n",
    "    llm_config = {\"config_list\": config_list},\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "\n",
    "#### START OF THE CHAT ####\n",
    "question.initiate_chat(\n",
    "    coder,\n",
    "    message = \"explain with rhymes what are the differences between pocahontas and matrix\",\n",
    "    max_turns = 4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
