{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, register_function, config_list_from_json\n",
    "from tools import * # Imports all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will 'connect' to the llama3.1 model running on llm container\n",
    "config_list = config_list_from_json(env_or_file=\"CONFIG_LIST\", filter_dict={\"model\": \"llama3.1\"})\n",
    "\n",
    "\n",
    "# This simple prompt will give some advice to the model on how to do things\n",
    "prompt = \"\"\"You are a movie expert providing information about movies.\n",
    "Be as helpful as possible and return as much information as possible.\n",
    "\n",
    "Do not answer any questions that do not relate to movies or actors.\n",
    "You must only use movies and actors in the graph and you must not use your previous knowledge.\n",
    "\n",
    "TOOLS: \n",
    "You must only use the provided functions in rag_tools module to answer.\n",
    "If you want only one result from plot_searcher you need to access one of the element it the list. \n",
    "If the context is not provided and you have more results you can choose randomly wich one to display.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mgraph_tool\u001b[0m (to graph_driver):\n",
      "\n",
      "What is the title of a movie that talks about romance?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 09-02 13:37:44] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mgraph_driver\u001b[0m (to graph_tool):\n",
      "\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_63dxsskx): plot_searcher *****\u001b[0m\n",
      "Arguments: \n",
      "{\"word\":\"romance\"}\n",
      "\u001b[32m**************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION plot_searcher...\u001b[0m\n",
      "\u001b[33mgraph_tool\u001b[0m (to graph_driver):\n",
      "\n",
      "\u001b[33mgraph_tool\u001b[0m (to graph_driver):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_63dxsskx) *****\u001b[0m\n",
      "[[\"How to Make an American Quilt\"], [\"Pocahontas\"]]\n",
      "\u001b[32m******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "[autogen.oai.client: 09-02 13:38:16] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mgraph_driver\u001b[0m (to graph_tool):\n",
      "\n",
      "Based on my search, I found that one movie that talks about romance is \"How to Make an American Quilt,\" which seems to have romantic elements in it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'What is the title of a movie that talks about romance?', 'role': 'assistant', 'name': 'graph_tool'}, {'content': '', 'tool_calls': [{'id': 'call_63dxsskx', 'function': {'arguments': '{\"word\":\"romance\"}', 'name': 'plot_searcher'}, 'type': 'function'}], 'role': 'assistant'}, {'content': '[[\"How to Make an American Quilt\"], [\"Pocahontas\"]]', 'tool_responses': [{'tool_call_id': 'call_63dxsskx', 'role': 'tool', 'content': '[[\"How to Make an American Quilt\"], [\"Pocahontas\"]]'}], 'role': 'tool', 'name': 'graph_tool'}, {'content': 'Based on my search, I found that one movie that talks about romance is \"How to Make an American Quilt,\" which seems to have romantic elements in it.', 'role': 'user', 'name': 'graph_driver'}], summary='Based on my search, I found that one movie that talks about romance is \"How to Make an American Quilt,\" which seems to have romantic elements in it.', cost={'usage_including_cached_inference': {'total_cost': 0, 'llama3.1': {'cost': 0, 'prompt_tokens': 584, 'completion_tokens': 53, 'total_tokens': 637}}, 'usage_excluding_cached_inference': {'total_cost': 0, 'llama3.1': {'cost': 0, 'prompt_tokens': 584, 'completion_tokens': 53, 'total_tokens': 637}}}, human_input=[])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This agent will start the conversation asking a simple question\n",
    "graph_tool = ConversableAgent(\n",
    "    \"graph_tool\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config=False,\n",
    "    # is_termination_msg=lambda msg: \"terminate\" in msg[\"content\"].lower(),\n",
    ")\n",
    "\n",
    "# This agent will try to answer the question \n",
    "graph_driver = ConversableAgent(\n",
    "    \"graph_driver\",\n",
    "    system_message = prompt,\n",
    "    llm_config = {\"config_list\": config_list},\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "# Register the plot_searcher to be used by the agents\n",
    "register_function(\n",
    "    plot_searcher,\n",
    "    caller = graph_driver,\n",
    "    executor = graph_tool,\n",
    "    description = \"searches a string in the plot of a movie. this service only receive a string to search and it will output all the titles of the movies containing the searched string.\"\n",
    ")\n",
    "\n",
    "# This will ask the driver to answer to one question \n",
    "graph_tool.initiate_chat(\n",
    "    graph_driver,\n",
    "    message = \"What is the title of a movie that talks about romance?\",\n",
    "    max_turns = 2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
