{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI-AGENT SYSTEM\n",
    "\n",
    "This system has 2-3 agents:\n",
    "- coder, this is the one that has to generate a cypher query\n",
    "- executor, this is the one that test the query on a neo4j database\n",
    "- retriever, this is the agent that will pass the documents to be used by coder. It cannot be considered as a part of the system because it only initiate the chat with the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, GroupChatManager, GroupChat, config_list_from_json\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent, TEXT_FORMATS\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from CypherExecutor import CypherCodeExecutor\n",
    "from neo4j_tools import save_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save database schema and then store the path to the directory\n",
    "save_schema()\n",
    "p = Path(__name__).parent.resolve() / \"schemas\"\n",
    "\n",
    "\n",
    "#### LLM MODEL CONFIGURATION #####\n",
    "\n",
    "config_list = config_list_from_json(env_or_file=\"CONFIG_LIST\", filter_dict={\"model\": \"gpt-4o\"})\n",
    "config_list[0][\"api_key\"] = os.environ.get(\"GITHUB_TOKEN\")\n",
    "\n",
    "llm_config = {\"config_list\": config_list, \"temperature\": 0.2}\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an AI helpful assistant.\n",
    "\n",
    "### RULES ###\n",
    "    - You have to explain everything you do.\n",
    "    - When the question refers to something that is contained \n",
    "      in the database you must generate 1 query to retrieve data.\n",
    "    - When generating a query you must use the Cypher format.\n",
    "\n",
    "### TERMINATION ###\n",
    "You can add 'TERMINATE' at the end of your message if:\n",
    "    - exitcode is 0 and you explained the output.\n",
    "    - exitcode is 1 and the error is not fixable with another query.\n",
    "    - there is not a query to execute.\n",
    "\n",
    "### DATABASE SCHEMA ### \n",
    "{input_context}\n",
    "\n",
    "### QUESTION ###\n",
    "{input_question}\n",
    "\"\"\"\n",
    "\n",
    "# This are the accepted formats that can be retrieved by RetrieveUserProxy\n",
    "print(f'Accepted formats for \"docs_path\": \\n{TEXT_FORMATS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termination_msg(x):\n",
    "    return isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n",
    "\n",
    "\n",
    "#TODO: useful pdf files at https://neo4j.com/docs/docs-archive/\n",
    "doc_retriever = RetrieveUserProxyAgent(\n",
    "    name=\"doc_retriever\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    max_consecutive_auto_reply=3,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    retrieve_config={\n",
    "        \"docs_path\": str(p), # A list of urls, dirs or files can be passed\n",
    "        \"extra-docs\": True,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"get_or_create\": True,\n",
    "        \"customized_prompt\": prompt\n",
    "    },\n",
    "    code_execution_config=False,\n",
    "    description=\"Assistant who has extra content retrieval power for solving cypher queries.\"\n",
    ")\n",
    "\n",
    "# Coder generates cypher queries with the help of the db schema \n",
    "coder      = AssistantAgent(\n",
    "    name=\"coder\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=prompt,\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Executor runs the query in a jupyter notebook\n",
    "executor   = AssistantAgent(\n",
    "    name=\"executor\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    human_input_mode=\"NEVER\", # THIS IS NOT SECURE! \n",
    "    description= \"\"\"Executor provides feedback based on the result of the query.\"\"\",\n",
    "    code_execution_config={\"executor\": CypherCodeExecutor()}\n",
    "    )\n",
    "\n",
    "# A question to be translated in cypher query language\n",
    "PROBLEM  = \"Explain with rhymes what are the differences between Pocahontas and Sabrina\"\n",
    "\n",
    "def _reset_agents():\n",
    "    \"\"\"\n",
    "    This function reset all the agents used for the group chat.\n",
    "    This should be used every time you start a new conversation.\n",
    "    \"\"\"\n",
    "    doc_retriever.reset()\n",
    "    coder.reset()\n",
    "    executor.reset()\n",
    "\n",
    "def state_transition(last_speaker, groupchat):\n",
    "    \"\"\"\n",
    "    This function simply return the next speaker based on the last one.\n",
    "    In this case we decided that doc_retriever should speak only to initiate chat\n",
    "    and then the chat is from coder to executor in a sort of loop.\n",
    "    \"\"\"\n",
    "    if   last_speaker is coder: return executor\n",
    "    elif last_speaker is executor: return coder\n",
    "    elif last_speaker is doc_retriever: return coder\n",
    "\n",
    "def rag_chat():\n",
    "    \"\"\"\n",
    "    Resets the agents, creates the group chat and then initiate chat.\n",
    "    The first agent to speak is the doc_retriever that will only pass:\n",
    "        - prompt\n",
    "        - files (like the schema), that is the context\n",
    "        - question\n",
    "    \"\"\"\n",
    "    _reset_agents()\n",
    "    groupchat = GroupChat(agents=[doc_retriever, coder, executor], messages=[], \n",
    "                          max_round=5, speaker_selection_method=state_transition)\n",
    "    manager   = GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "    doc_retriever.initiate_chat(manager,message=doc_retriever.message_generator, problem=PROBLEM,n_results=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### START OF THE GROUP CHAT BETWEEN CODER AND EXECUTOR ####\n",
    "rag_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
