{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI-AGENT SYSTEM\n",
    "\n",
    "This system has 2-3 agents:\n",
    "- coder, this is the one that has to generate a cypher query\n",
    "- executor, this is the one that test the query on a neo4j database\n",
    "- retriever, this is the agent that will pass the documents to be used by coder. It cannot be considered as a part of the system because it only initiate the chat with the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, GroupChatManager, GroupChat, config_list_from_json\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent, TEXT_FORMATS\n",
    "\n",
    "from CypherExecutor import CypherCodeExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted formats for \"docs_path\": \n",
      "['txt', 'json', 'csv', 'tsv', 'md', 'html', 'htm', 'rtf', 'rst', 'jsonl', 'log', 'xml', 'yaml', 'yml', 'pdf']\n"
     ]
    }
   ],
   "source": [
    "# This list will 'connect' to the llama3.1 model running on llm container\n",
    "config_list = config_list_from_json(env_or_file=\"CONFIG_LIST\", filter_dict={\"model\": \"llama3.1\"})\n",
    "\n",
    "\n",
    "llm_config = {\"config_list\": config_list, \"temperature\": 0.2}\n",
    "\n",
    "prompt = \"\"\"You are a data scientist that works with Cypher queries.\n",
    "Your work is to translate the given answer as Cypher queries.\n",
    "\n",
    "You have some rules to respect:\n",
    "- You must use cypher language.\n",
    "- You can use the pdf files. \n",
    "- You must generate the easiest cypher query possible.\n",
    "- Every query must be in a separate cypher format.\n",
    "- You must be precise and explain everything, code outputs too. \n",
    "- If the code runs successfully you can send 'TERMINATE'.\n",
    "\n",
    "Now i will give you some information about the database schema.\n",
    "- nodes -\n",
    "(:Movie), Describe a movie with a title and a plot. It may have the number of likes.\n",
    "(:Person), Describe actors and directors. They have a name and a birthday.\n",
    "\n",
    "- relationships -\n",
    "(:Person) -[:ACTED_IN]-> (:Movie)\n",
    "\n",
    "QUESTION IS:\n",
    "{input_question}\n",
    "\"\"\"\n",
    "\n",
    "print(f'Accepted formats for \"docs_path\": \\n{TEXT_FORMATS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termination_msg(x):\n",
    "    return isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n",
    "\n",
    "doc_retriever = RetrieveUserProxyAgent(\n",
    "    name=\"doc_retriever\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    max_consecutive_auto_reply=3,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    retrieve_config={\n",
    "        \"task\": \"code\",\n",
    "        \"docs_path\": \"https://s3.amazonaws.com/artifacts.opencypher.org/openCypher9.pdf\",\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"get_or_create\": True,\n",
    "        \"customized_prompt\": prompt\n",
    "    },\n",
    "    code_execution_config=False,\n",
    "    description=\"Assistant who has extra content retrieval power for solving cypher queries.\"\n",
    ")\n",
    "\n",
    "coder      = AssistantAgent(\n",
    "    name=\"coder\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=prompt,\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "executor   = AssistantAgent(\n",
    "    name=\"executor\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    description= \"\"\"Executor provides feedback based on the result of the query.\"\"\",\n",
    "    code_execution_config={\"executor\": CypherCodeExecutor()}\n",
    "    )\n",
    "\n",
    "\n",
    "PROBLEM  = \"Who directed Matrix?\"\n",
    "\n",
    "def _reset_agents():\n",
    "    \"\"\"\n",
    "    This function reset all the agents used for the group chat.\n",
    "    This should be used every time you start a new conversation.\n",
    "    \"\"\"\n",
    "    doc_retriever.reset()\n",
    "    coder.reset()\n",
    "    executor.reset()\n",
    "\n",
    "def state_transition(last_speaker, groupchat):\n",
    "    \"\"\"\n",
    "    This function simply return the next speaker based on the last one.\n",
    "    In this case we decided that doc_retriever should speak only to initiate chat\n",
    "    and then the chat is from coder to executor in a sort of loop.\n",
    "    \"\"\"\n",
    "    if   last_speaker is coder: return executor\n",
    "    elif last_speaker is executor: return coder\n",
    "    elif last_speaker is doc_retriever: return coder\n",
    "\n",
    "def rag_chat():\n",
    "    _reset_agents()\n",
    "    groupchat = GroupChat(agents=[doc_retriever, coder, executor], messages=[], \n",
    "                          max_round=5, speaker_selection_method=state_transition)\n",
    "    manager   = GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "    doc_retriever.initiate_chat(manager,message=doc_retriever.message_generator, problem=PROBLEM,n_results=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
