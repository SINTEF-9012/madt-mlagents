{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RETRIEVE AGENT\n",
    "\n",
    "This add a retrieve agent to the simple_agent.\n",
    "RetrieveUserProxyAgent can pass documents (many formats are supported) that can be used by the coder.\n",
    "This should help to improve the generation of the query.\n",
    "The model we are using has already some knowledge on how to generate cypher code so we decided to not give some rules like \"You must use only the provided documents\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, config_list_from_json\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent, TEXT_FORMATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted formats for \"docs_path\": \n",
      "['txt', 'json', 'csv', 'tsv', 'md', 'html', 'htm', 'rtf', 'rst', 'jsonl', 'log', 'xml', 'yaml', 'yml', 'pdf']\n"
     ]
    }
   ],
   "source": [
    "# This list will 'connect' to the llama3.1 model running on llm container\n",
    "config_list = config_list_from_json(env_or_file=\"CONFIG_LIST\", filter_dict={\"model\": \"llama3.1\"})\n",
    "\n",
    "llm_config = {\"config_list\": config_list, \"temperature\": 0.2}\n",
    "\n",
    "prompt = \"\"\"You are a data scientist that works with Cypher queries.\n",
    "All you have to do is translate the given answer as Cypher queries.\n",
    "\n",
    "You have to respect this rules:\n",
    "- You must use the pdf files. \n",
    "- You must generate the easiest query possible in cypher format.\n",
    "- You must instert all the information you have and where you found them.\n",
    "- You must be precise. \n",
    "- You must re-generate the query if you think it could generates some errors.\n",
    "\n",
    "Now i will give you some information about the database schema.\n",
    "- nodes -\n",
    "(:Movie), Describe a movie that has a title and a plot. It can also have the number of likes.\n",
    "(:Person), Describe actors and directors. They have a name, a birthday and they may also have the death date.\n",
    "\n",
    "- relationships -\n",
    "(:Movie) <-[:DIRECTED]- (:Person)\n",
    "(:Person) -[:ACTED-IN]-> (:Movie)\n",
    "(:Person) -[:KNOWS]-> (:Person)\n",
    "(:Movie) -[:type]-> (:Genre)\n",
    "\n",
    "When you think the query can be run you can submit it as the final answer.\n",
    "When you have written your final answer you must send 'TERMINATE'.\n",
    "\n",
    "\n",
    "QUESTION IS:\n",
    "{input_question}\n",
    "\"\"\"\n",
    "\n",
    "print(f'Accepted formats for \"docs_path\": \\n{TEXT_FORMATS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termination_msg(x):\n",
    "    return isinstance(x, dict) and \"TERMINATE\" == str(x.get(\"content\", \"\"))[-9:].upper()\n",
    "\n",
    "doc_retriever = RetrieveUserProxyAgent(\n",
    "    name=\"doc_retriever\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    max_consecutive_auto_reply=3,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    retrieve_config={\n",
    "        \"docs_path\": \"https://s3.amazonaws.com/artifacts.opencypher.org/openCypher9.pdf\",\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"get_or_create\": True,\n",
    "        \"customized_prompt\": prompt\n",
    "    },\n",
    "    code_execution_config=False,  \n",
    "    description=\"Assistant who has extra content retrieval power for solving difficult problems.\",\n",
    ")\n",
    "\n",
    "\n",
    "coder   = AssistantAgent(\n",
    "    name=\"coder\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=prompt,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")\n",
    "\n",
    "PROBLEM = \"How can i retrieve all the nodes of one type?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 09:18:47,467 - autogen.agentchat.contrib.retrieve_user_proxy_agent - INFO - \u001b[32mUse the existing collection `autogen-docs`.\u001b[0m\n",
      "max_tokens is too small to fit a single line of text. Breaking this line:\n",
      "\t          ...\n",
      "Failed to split docs with must_break_at_empty_line being True, set to False.\n",
      "2024-09-09 09:18:58,465 - autogen.agentchat.contrib.retrieve_user_proxy_agent - INFO - Found 287 chunks.\u001b[0m\n",
      "Model llama3.1 not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorDB returns doc_ids:  [['926c7940', '08ef1daa', 'fd25d579']]\n",
      "\u001b[32mAdding content of doc 926c7940 to context.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3.1 not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAdding content of doc 08ef1daa to context.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model llama3.1 not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mdoc_retriever\u001b[0m (to coder):\n",
      "\n",
      "You are a data scientist that works with Cypher queries.\n",
      "All you have to do is translate the given answer as Cypher queries.\n",
      "\n",
      "You have to respect this rules:\n",
      "- You must use the pdf files. \n",
      "- You must generate the easiest query possible in markdown format.\n",
      "- You must instert all the information you have and where you found them.\n",
      "- You must be precise. \n",
      "- You must re-generate the query if you think it could generates some errors.\n",
      "\n",
      "Now i will give you some information about the database schema.\n",
      "- nodes -\n",
      "(:Movie), Describe a movie that has a title and a plot. It can also have the number of likes.\n",
      "(:Person), Describe actors and directors. They have a name, a birthday and they may also have the death date.\n",
      "\n",
      "- relationships -\n",
      "(:Movie) <-[:DIRECTED]- (:Person)\n",
      "(:Person) -[:ACTED-IN]-> (:Movie)\n",
      "(:Person) -[:KNOWS]-> (:Person)\n",
      "(:Movie) -[:type]-> (:Genre)\n",
      "\n",
      "When you think the query can be run you can submit it as the final answer.\n",
      "When you have written your final answer you must send 'TERMINATE'.\n",
      "\n",
      "\n",
      "QUESTION IS:\n",
      "\n",
      "How can i retrieve all the nodes of one type?\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 09-09 09:22:24] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mcoder\u001b[0m (to doc_retriever):\n",
      "\n",
      "## Retrieving All Nodes of One Type\n",
      "\n",
      "To retrieve all nodes of a specific type, we can use the `MATCH` clause with the `OPTIONAL MATCH` pattern.\n",
      "\n",
      "### For Movies\n",
      "```cypher\n",
      "MATCH (m:Movie)\n",
      "RETURN m;\n",
      "```\n",
      "This query will return all movie nodes in the database.\n",
      "\n",
      "### For People\n",
      "```cypher\n",
      "MATCH (p:Person)\n",
      "RETURN p;\n",
      "```\n",
      "This query will return all person nodes in the database.\n",
      "\n",
      "Note that we're using the `OPTIONAL MATCH` pattern to match any node of type `Movie` or `Person`, and then returning the matched nodes. This approach ensures that we retrieve all nodes of the specified type, even if they don't have any relationships with other nodes.\n",
      "\n",
      "**Source:** The Cypher query syntax is based on the official Neo4j documentation for Cypher queries: <https://neo4j.com/docs/cypherdsl/current/>\n",
      "\n",
      "Please let me know if you'd like to proceed with the next question or if I should submit this as the final answer.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mdoc_retriever\u001b[0m (to coder):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 09-09 09:22:34] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mcoder\u001b[0m (to doc_retriever):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"You are a data scientist that works with Cypher queries.\\nAll you have to do is translate the given answer as Cypher queries.\\n\\nYou have to respect this rules:\\n- You must use the pdf files. \\n- You must generate the easiest query possible in markdown format.\\n- You must instert all the information you have and where you found them.\\n- You must be precise. \\n- You must re-generate the query if you think it could generates some errors.\\n\\nNow i will give you some information about the database schema.\\n- nodes -\\n(:Movie), Describe a movie that has a title and a plot. It can also have the number of likes.\\n(:Person), Describe actors and directors. They have a name, a birthday and they may also have the death date.\\n\\n- relationships -\\n(:Movie) <-[:DIRECTED]- (:Person)\\n(:Person) -[:ACTED-IN]-> (:Movie)\\n(:Person) -[:KNOWS]-> (:Person)\\n(:Movie) -[:type]-> (:Genre)\\n\\nWhen you think the query can be run you can submit it as the final answer.\\nWhen you have written your final answer you must send 'TERMINATE'.\\n\\n\\nQUESTION IS:\\n\\nHow can i retrieve all the nodes of one type?\\n\", 'role': 'assistant', 'name': 'doc_retriever'}, {'content': \"## Retrieving All Nodes of One Type\\n\\nTo retrieve all nodes of a specific type, we can use the `MATCH` clause with the `OPTIONAL MATCH` pattern.\\n\\n### For Movies\\n```cypher\\nMATCH (m:Movie)\\nRETURN m;\\n```\\nThis query will return all movie nodes in the database.\\n\\n### For People\\n```cypher\\nMATCH (p:Person)\\nRETURN p;\\n```\\nThis query will return all person nodes in the database.\\n\\nNote that we're using the `OPTIONAL MATCH` pattern to match any node of type `Movie` or `Person`, and then returning the matched nodes. This approach ensures that we retrieve all nodes of the specified type, even if they don't have any relationships with other nodes.\\n\\n**Source:** The Cypher query syntax is based on the official Neo4j documentation for Cypher queries: <https://neo4j.com/docs/cypherdsl/current/>\\n\\nPlease let me know if you'd like to proceed with the next question or if I should submit this as the final answer.\", 'role': 'user', 'name': 'coder'}, {'content': '', 'role': 'assistant', 'name': 'doc_retriever'}, {'content': 'TERMINATE', 'role': 'user', 'name': 'coder'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0, 'llama3.1': {'cost': 0, 'prompt_tokens': 1247, 'completion_tokens': 218, 'total_tokens': 1465}}, 'usage_excluding_cached_inference': {'total_cost': 0, 'llama3.1': {'cost': 0, 'prompt_tokens': 1247, 'completion_tokens': 218, 'total_tokens': 1465}}}, human_input=[])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_retriever.reset()\n",
    "coder.reset()\n",
    "\n",
    "doc_retriever.initiate_chat(coder, message=doc_retriever.message_generator, problem=PROBLEM, max_turns=5, n_results=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
